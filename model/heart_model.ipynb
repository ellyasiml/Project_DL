{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw8kRrbJOc25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/dataset/dataset Deep Learning/heart.csv\")"
      ],
      "metadata": {
        "id": "8AmC_ERZQrcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(df['output']==1))\n",
        "print(sum(df['output']==0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U2K9WQ9m8-p",
        "outputId": "6746d153-3f00-417d-f67d-25bbfeaa99a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "165\n",
            "138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_columns = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall', 'output']\n",
        "df[cat_columns] = df[cat_columns].astype(str)"
      ],
      "metadata": {
        "id": "D_vNf3Ri-bOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, drop_first=True)"
      ],
      "metadata": {
        "id": "d_ni7td--2V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "a5xujJbP-iWG",
        "outputId": "c351feed-3139-4975-a7d7-b05649ef57f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  trtbps  chol  thalachh  oldpeak  sex_1  cp_1  cp_2  cp_3  fbs_1  ...  \\\n",
              "0   63     145   233       150      2.3      1     0     0     1      1  ...   \n",
              "1   37     130   250       187      3.5      1     0     1     0      0  ...   \n",
              "2   41     130   204       172      1.4      0     1     0     0      0  ...   \n",
              "3   56     120   236       178      0.8      1     1     0     0      0  ...   \n",
              "4   57     120   354       163      0.6      0     0     0     0      0  ...   \n",
              "\n",
              "   slp_1  slp_2  caa_1  caa_2  caa_3  caa_4  thall_1  thall_2  thall_3  \\\n",
              "0      0      0      0      0      0      0        1        0        0   \n",
              "1      0      0      0      0      0      0        0        1        0   \n",
              "2      0      1      0      0      0      0        0        1        0   \n",
              "3      0      1      0      0      0      0        0        1        0   \n",
              "4      0      1      0      0      0      0        0        1        0   \n",
              "\n",
              "   output_1  \n",
              "0         1  \n",
              "1         1  \n",
              "2         1  \n",
              "3         1  \n",
              "4         1  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccd6ce3d-5115-4b24-b3f8-c305467e50ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>fbs_1</th>\n",
              "      <th>...</th>\n",
              "      <th>slp_1</th>\n",
              "      <th>slp_2</th>\n",
              "      <th>caa_1</th>\n",
              "      <th>caa_2</th>\n",
              "      <th>caa_3</th>\n",
              "      <th>caa_4</th>\n",
              "      <th>thall_1</th>\n",
              "      <th>thall_2</th>\n",
              "      <th>thall_3</th>\n",
              "      <th>output_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>150</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>187</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>172</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>178</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>163</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccd6ce3d-5115-4b24-b3f8-c305467e50ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccd6ce3d-5115-4b24-b3f8-c305467e50ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccd6ce3d-5115-4b24-b3f8-c305467e50ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p-KQ0UEMu0w",
        "outputId": "cda892e7-c286-4727-b273-153a8b5a8b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trtbps      0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalachh    0\n",
              "exng        0\n",
              "oldpeak     0\n",
              "slp         0\n",
              "caa         0\n",
              "thall       0\n",
              "output      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:, 0:-1].values\n",
        "\n",
        "y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "KjkRWEGXVYkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)"
      ],
      "metadata": {
        "id": "4E04u7vXdaCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2,random_state= 42)"
      ],
      "metadata": {
        "id": "NbKv_GhGAgv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128,activation='relu',input_shape=(22,)))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nzZJ2-qNa2oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "cb = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    min_delta=0.001,\n",
        "    patience=100,\n",
        "    verbose=1,\n",
        "    mode='auto')"
      ],
      "metadata": {
        "id": "rFMDpqghbLFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,epochs=2000,batch_size=10000,validation_split=0.10,callbacks=cb)"
      ],
      "metadata": {
        "id": "usN0TdpebVY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddc32c3-5074-447a-84d3-6b5644d665b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.7126 - accuracy: 0.5484 - val_loss: 0.6641 - val_accuracy: 0.6800\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7244 - accuracy: 0.5207 - val_loss: 0.6639 - val_accuracy: 0.6800\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7171 - accuracy: 0.5392 - val_loss: 0.6637 - val_accuracy: 0.6800\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7126 - accuracy: 0.5530 - val_loss: 0.6636 - val_accuracy: 0.6800\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7202 - accuracy: 0.5438 - val_loss: 0.6634 - val_accuracy: 0.6800\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7190 - accuracy: 0.5530 - val_loss: 0.6632 - val_accuracy: 0.6800\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7216 - accuracy: 0.5714 - val_loss: 0.6631 - val_accuracy: 0.6800\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7140 - accuracy: 0.5300 - val_loss: 0.6629 - val_accuracy: 0.6800\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7224 - accuracy: 0.5576 - val_loss: 0.6628 - val_accuracy: 0.6800\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7185 - accuracy: 0.5392 - val_loss: 0.6626 - val_accuracy: 0.6800\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7021 - accuracy: 0.5484 - val_loss: 0.6624 - val_accuracy: 0.6800\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7167 - accuracy: 0.5438 - val_loss: 0.6623 - val_accuracy: 0.6800\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7134 - accuracy: 0.5346 - val_loss: 0.6621 - val_accuracy: 0.6800\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6994 - accuracy: 0.5530 - val_loss: 0.6620 - val_accuracy: 0.6800\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.7009 - accuracy: 0.5714 - val_loss: 0.6618 - val_accuracy: 0.6800\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7055 - accuracy: 0.5300 - val_loss: 0.6616 - val_accuracy: 0.6800\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7175 - accuracy: 0.5207 - val_loss: 0.6615 - val_accuracy: 0.6800\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7098 - accuracy: 0.5438 - val_loss: 0.6613 - val_accuracy: 0.6800\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6982 - accuracy: 0.5760 - val_loss: 0.6611 - val_accuracy: 0.6800\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7095 - accuracy: 0.5346 - val_loss: 0.6610 - val_accuracy: 0.6800\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7122 - accuracy: 0.5253 - val_loss: 0.6608 - val_accuracy: 0.6800\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7096 - accuracy: 0.5161 - val_loss: 0.6607 - val_accuracy: 0.6800\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7049 - accuracy: 0.5576 - val_loss: 0.6605 - val_accuracy: 0.6800\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7124 - accuracy: 0.5300 - val_loss: 0.6604 - val_accuracy: 0.6800\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7048 - accuracy: 0.5576 - val_loss: 0.6602 - val_accuracy: 0.6800\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7263 - accuracy: 0.5161 - val_loss: 0.6600 - val_accuracy: 0.6800\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7015 - accuracy: 0.5484 - val_loss: 0.6599 - val_accuracy: 0.6800\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7137 - accuracy: 0.5668 - val_loss: 0.6597 - val_accuracy: 0.6800\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7170 - accuracy: 0.5115 - val_loss: 0.6596 - val_accuracy: 0.6800\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7030 - accuracy: 0.5300 - val_loss: 0.6594 - val_accuracy: 0.7200\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7102 - accuracy: 0.5530 - val_loss: 0.6593 - val_accuracy: 0.7200\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7197 - accuracy: 0.5392 - val_loss: 0.6591 - val_accuracy: 0.7200\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.7135 - accuracy: 0.5069 - val_loss: 0.6590 - val_accuracy: 0.7200\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7244 - accuracy: 0.5115 - val_loss: 0.6588 - val_accuracy: 0.7200\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7150 - accuracy: 0.5622 - val_loss: 0.6586 - val_accuracy: 0.7200\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7112 - accuracy: 0.5576 - val_loss: 0.6585 - val_accuracy: 0.7200\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6972 - accuracy: 0.5438 - val_loss: 0.6583 - val_accuracy: 0.7200\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6995 - accuracy: 0.5622 - val_loss: 0.6582 - val_accuracy: 0.7200\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7261 - accuracy: 0.5346 - val_loss: 0.6580 - val_accuracy: 0.7200\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7000 - accuracy: 0.5760 - val_loss: 0.6579 - val_accuracy: 0.7200\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7130 - accuracy: 0.5484 - val_loss: 0.6577 - val_accuracy: 0.7200\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6985 - accuracy: 0.5714 - val_loss: 0.6576 - val_accuracy: 0.7200\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7176 - accuracy: 0.5253 - val_loss: 0.6574 - val_accuracy: 0.7200\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7034 - accuracy: 0.5668 - val_loss: 0.6573 - val_accuracy: 0.7200\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7076 - accuracy: 0.5576 - val_loss: 0.6571 - val_accuracy: 0.7200\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7177 - accuracy: 0.5392 - val_loss: 0.6570 - val_accuracy: 0.7200\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7155 - accuracy: 0.5576 - val_loss: 0.6568 - val_accuracy: 0.7200\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7059 - accuracy: 0.5253 - val_loss: 0.6567 - val_accuracy: 0.7200\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6936 - accuracy: 0.5530 - val_loss: 0.6565 - val_accuracy: 0.7200\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7121 - accuracy: 0.5392 - val_loss: 0.6564 - val_accuracy: 0.7200\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7168 - accuracy: 0.5253 - val_loss: 0.6562 - val_accuracy: 0.7200\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6905 - accuracy: 0.5622 - val_loss: 0.6561 - val_accuracy: 0.7200\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6994 - accuracy: 0.5438 - val_loss: 0.6559 - val_accuracy: 0.7200\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6989 - accuracy: 0.5438 - val_loss: 0.6558 - val_accuracy: 0.7200\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7141 - accuracy: 0.5438 - val_loss: 0.6556 - val_accuracy: 0.7200\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6998 - accuracy: 0.5714 - val_loss: 0.6555 - val_accuracy: 0.7200\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7007 - accuracy: 0.5530 - val_loss: 0.6553 - val_accuracy: 0.7200\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7255 - accuracy: 0.5253 - val_loss: 0.6552 - val_accuracy: 0.7200\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7034 - accuracy: 0.5622 - val_loss: 0.6550 - val_accuracy: 0.7200\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7030 - accuracy: 0.5714 - val_loss: 0.6548 - val_accuracy: 0.7200\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7035 - accuracy: 0.5069 - val_loss: 0.6547 - val_accuracy: 0.7200\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7141 - accuracy: 0.5207 - val_loss: 0.6545 - val_accuracy: 0.7200\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7096 - accuracy: 0.5438 - val_loss: 0.6544 - val_accuracy: 0.7200\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6992 - accuracy: 0.5484 - val_loss: 0.6542 - val_accuracy: 0.7200\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6980 - accuracy: 0.5392 - val_loss: 0.6541 - val_accuracy: 0.7200\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7045 - accuracy: 0.5392 - val_loss: 0.6539 - val_accuracy: 0.7200\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6945 - accuracy: 0.5392 - val_loss: 0.6537 - val_accuracy: 0.7200\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.5668 - val_loss: 0.6536 - val_accuracy: 0.7200\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6987 - accuracy: 0.5392 - val_loss: 0.6534 - val_accuracy: 0.7200\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.7113 - accuracy: 0.5530 - val_loss: 0.6533 - val_accuracy: 0.7200\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6905 - accuracy: 0.5530 - val_loss: 0.6531 - val_accuracy: 0.7200\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6950 - accuracy: 0.5392 - val_loss: 0.6530 - val_accuracy: 0.7200\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7226 - accuracy: 0.5300 - val_loss: 0.6528 - val_accuracy: 0.7200\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6901 - accuracy: 0.5668 - val_loss: 0.6527 - val_accuracy: 0.7200\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6961 - accuracy: 0.5622 - val_loss: 0.6525 - val_accuracy: 0.7200\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6885 - accuracy: 0.5668 - val_loss: 0.6524 - val_accuracy: 0.7200\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5622 - val_loss: 0.6522 - val_accuracy: 0.7200\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6956 - accuracy: 0.5622 - val_loss: 0.6521 - val_accuracy: 0.7200\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6949 - accuracy: 0.5668 - val_loss: 0.6520 - val_accuracy: 0.7200\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7002 - accuracy: 0.5899 - val_loss: 0.6518 - val_accuracy: 0.7200\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6991 - accuracy: 0.5161 - val_loss: 0.6516 - val_accuracy: 0.7200\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6919 - accuracy: 0.5991 - val_loss: 0.6515 - val_accuracy: 0.7200\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6960 - accuracy: 0.5806 - val_loss: 0.6513 - val_accuracy: 0.7200\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6906 - accuracy: 0.5714 - val_loss: 0.6512 - val_accuracy: 0.7200\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7142 - accuracy: 0.5161 - val_loss: 0.6511 - val_accuracy: 0.7200\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.7204 - accuracy: 0.5023 - val_loss: 0.6509 - val_accuracy: 0.7200\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7074 - accuracy: 0.5576 - val_loss: 0.6508 - val_accuracy: 0.7200\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7039 - accuracy: 0.5392 - val_loss: 0.6506 - val_accuracy: 0.7200\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6870 - accuracy: 0.5806 - val_loss: 0.6505 - val_accuracy: 0.7200\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.7023 - accuracy: 0.5392 - val_loss: 0.6503 - val_accuracy: 0.7200\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6992 - accuracy: 0.5668 - val_loss: 0.6501 - val_accuracy: 0.7200\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7005 - accuracy: 0.5668 - val_loss: 0.6500 - val_accuracy: 0.7200\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6973 - accuracy: 0.5530 - val_loss: 0.6498 - val_accuracy: 0.7200\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6845 - accuracy: 0.5530 - val_loss: 0.6497 - val_accuracy: 0.7200\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6962 - accuracy: 0.5806 - val_loss: 0.6496 - val_accuracy: 0.7200\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6916 - accuracy: 0.5668 - val_loss: 0.6494 - val_accuracy: 0.7200\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7098 - accuracy: 0.5300 - val_loss: 0.6493 - val_accuracy: 0.7200\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7075 - accuracy: 0.5530 - val_loss: 0.6491 - val_accuracy: 0.7200\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6927 - accuracy: 0.5899 - val_loss: 0.6489 - val_accuracy: 0.7200\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6942 - accuracy: 0.5530 - val_loss: 0.6488 - val_accuracy: 0.7200\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6799 - accuracy: 0.5853 - val_loss: 0.6486 - val_accuracy: 0.7200\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6926 - accuracy: 0.5806 - val_loss: 0.6485 - val_accuracy: 0.7200\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6973 - accuracy: 0.5668 - val_loss: 0.6483 - val_accuracy: 0.7200\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6885 - accuracy: 0.5714 - val_loss: 0.6482 - val_accuracy: 0.7200\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6865 - accuracy: 0.5668 - val_loss: 0.6480 - val_accuracy: 0.7200\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6938 - accuracy: 0.5438 - val_loss: 0.6479 - val_accuracy: 0.7200\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6908 - accuracy: 0.5714 - val_loss: 0.6477 - val_accuracy: 0.7200\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6877 - accuracy: 0.5530 - val_loss: 0.6476 - val_accuracy: 0.7200\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7105 - accuracy: 0.5714 - val_loss: 0.6474 - val_accuracy: 0.7200\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6870 - accuracy: 0.5760 - val_loss: 0.6473 - val_accuracy: 0.7200\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7004 - accuracy: 0.5668 - val_loss: 0.6471 - val_accuracy: 0.7200\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6951 - accuracy: 0.5668 - val_loss: 0.6470 - val_accuracy: 0.7200\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6843 - accuracy: 0.5668 - val_loss: 0.6468 - val_accuracy: 0.7200\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6921 - accuracy: 0.5760 - val_loss: 0.6467 - val_accuracy: 0.7200\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6984 - accuracy: 0.5392 - val_loss: 0.6465 - val_accuracy: 0.7200\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6977 - accuracy: 0.5530 - val_loss: 0.6464 - val_accuracy: 0.7200\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6912 - accuracy: 0.5346 - val_loss: 0.6462 - val_accuracy: 0.7200\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7024 - accuracy: 0.5760 - val_loss: 0.6461 - val_accuracy: 0.7200\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6909 - accuracy: 0.5945 - val_loss: 0.6459 - val_accuracy: 0.7200\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6878 - accuracy: 0.5714 - val_loss: 0.6458 - val_accuracy: 0.7200\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6991 - accuracy: 0.5576 - val_loss: 0.6456 - val_accuracy: 0.7200\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6971 - accuracy: 0.5622 - val_loss: 0.6455 - val_accuracy: 0.7200\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6939 - accuracy: 0.5760 - val_loss: 0.6453 - val_accuracy: 0.7200\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6930 - accuracy: 0.5392 - val_loss: 0.6452 - val_accuracy: 0.7200\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7060 - accuracy: 0.5392 - val_loss: 0.6450 - val_accuracy: 0.7200\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6870 - accuracy: 0.5760 - val_loss: 0.6449 - val_accuracy: 0.7200\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6984 - accuracy: 0.5622 - val_loss: 0.6447 - val_accuracy: 0.7200\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6895 - accuracy: 0.5945 - val_loss: 0.6446 - val_accuracy: 0.7200\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6737 - accuracy: 0.5714 - val_loss: 0.6444 - val_accuracy: 0.7200\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6815 - accuracy: 0.5945 - val_loss: 0.6443 - val_accuracy: 0.7200\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6883 - accuracy: 0.5530 - val_loss: 0.6441 - val_accuracy: 0.7200\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6864 - accuracy: 0.5991 - val_loss: 0.6440 - val_accuracy: 0.7200\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6761 - accuracy: 0.5853 - val_loss: 0.6438 - val_accuracy: 0.7200\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6854 - accuracy: 0.5576 - val_loss: 0.6437 - val_accuracy: 0.7200\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6944 - accuracy: 0.5622 - val_loss: 0.6435 - val_accuracy: 0.7200\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6796 - accuracy: 0.5622 - val_loss: 0.6434 - val_accuracy: 0.7200\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6958 - accuracy: 0.5300 - val_loss: 0.6432 - val_accuracy: 0.7200\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6799 - accuracy: 0.5853 - val_loss: 0.6431 - val_accuracy: 0.7200\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6817 - accuracy: 0.5945 - val_loss: 0.6429 - val_accuracy: 0.7200\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6804 - accuracy: 0.5760 - val_loss: 0.6428 - val_accuracy: 0.7200\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6884 - accuracy: 0.5991 - val_loss: 0.6426 - val_accuracy: 0.7200\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6867 - accuracy: 0.5714 - val_loss: 0.6425 - val_accuracy: 0.7200\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6904 - accuracy: 0.5991 - val_loss: 0.6423 - val_accuracy: 0.7200\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6853 - accuracy: 0.5899 - val_loss: 0.6422 - val_accuracy: 0.7200\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6767 - accuracy: 0.5853 - val_loss: 0.6420 - val_accuracy: 0.7200\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6888 - accuracy: 0.6037 - val_loss: 0.6419 - val_accuracy: 0.7200\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6714 - accuracy: 0.5806 - val_loss: 0.6417 - val_accuracy: 0.7200\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6972 - accuracy: 0.5484 - val_loss: 0.6415 - val_accuracy: 0.7200\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6726 - accuracy: 0.6129 - val_loss: 0.6414 - val_accuracy: 0.7200\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6902 - accuracy: 0.5438 - val_loss: 0.6412 - val_accuracy: 0.7200\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7040 - accuracy: 0.5300 - val_loss: 0.6411 - val_accuracy: 0.7200\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6945 - accuracy: 0.5530 - val_loss: 0.6409 - val_accuracy: 0.7200\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6948 - accuracy: 0.5484 - val_loss: 0.6408 - val_accuracy: 0.7200\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6850 - accuracy: 0.5760 - val_loss: 0.6406 - val_accuracy: 0.7200\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6848 - accuracy: 0.5576 - val_loss: 0.6405 - val_accuracy: 0.7200\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6812 - accuracy: 0.5945 - val_loss: 0.6403 - val_accuracy: 0.7200\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6860 - accuracy: 0.5853 - val_loss: 0.6402 - val_accuracy: 0.7200\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6763 - accuracy: 0.5714 - val_loss: 0.6400 - val_accuracy: 0.7200\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6848 - accuracy: 0.5668 - val_loss: 0.6398 - val_accuracy: 0.7200\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6768 - accuracy: 0.5668 - val_loss: 0.6397 - val_accuracy: 0.7200\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6968 - accuracy: 0.5300 - val_loss: 0.6395 - val_accuracy: 0.7200\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6645 - accuracy: 0.5991 - val_loss: 0.6394 - val_accuracy: 0.7200\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6828 - accuracy: 0.5806 - val_loss: 0.6392 - val_accuracy: 0.7200\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6829 - accuracy: 0.5806 - val_loss: 0.6390 - val_accuracy: 0.7200\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6968 - accuracy: 0.5530 - val_loss: 0.6389 - val_accuracy: 0.7200\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6893 - accuracy: 0.5714 - val_loss: 0.6387 - val_accuracy: 0.7200\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6882 - accuracy: 0.5899 - val_loss: 0.6386 - val_accuracy: 0.7200\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6873 - accuracy: 0.5806 - val_loss: 0.6384 - val_accuracy: 0.7200\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6953 - accuracy: 0.5622 - val_loss: 0.6383 - val_accuracy: 0.7200\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7000 - accuracy: 0.5392 - val_loss: 0.6381 - val_accuracy: 0.7200\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6773 - accuracy: 0.5991 - val_loss: 0.6380 - val_accuracy: 0.7200\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6866 - accuracy: 0.5714 - val_loss: 0.6378 - val_accuracy: 0.7200\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6887 - accuracy: 0.5576 - val_loss: 0.6376 - val_accuracy: 0.7200\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6838 - accuracy: 0.5760 - val_loss: 0.6375 - val_accuracy: 0.7200\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6870 - accuracy: 0.5668 - val_loss: 0.6373 - val_accuracy: 0.7200\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6850 - accuracy: 0.5668 - val_loss: 0.6372 - val_accuracy: 0.7200\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6786 - accuracy: 0.6221 - val_loss: 0.6370 - val_accuracy: 0.7200\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6857 - accuracy: 0.5899 - val_loss: 0.6369 - val_accuracy: 0.7200\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6725 - accuracy: 0.5991 - val_loss: 0.6367 - val_accuracy: 0.7200\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6769 - accuracy: 0.5668 - val_loss: 0.6365 - val_accuracy: 0.7200\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6881 - accuracy: 0.5945 - val_loss: 0.6364 - val_accuracy: 0.7200\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6881 - accuracy: 0.5806 - val_loss: 0.6362 - val_accuracy: 0.7200\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6850 - accuracy: 0.5853 - val_loss: 0.6361 - val_accuracy: 0.7200\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6881 - accuracy: 0.5622 - val_loss: 0.6359 - val_accuracy: 0.7200\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6991 - accuracy: 0.5530 - val_loss: 0.6357 - val_accuracy: 0.7200\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6844 - accuracy: 0.5945 - val_loss: 0.6356 - val_accuracy: 0.7200\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6805 - accuracy: 0.5899 - val_loss: 0.6354 - val_accuracy: 0.7200\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6883 - accuracy: 0.6037 - val_loss: 0.6353 - val_accuracy: 0.7200\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6910 - accuracy: 0.5300 - val_loss: 0.6351 - val_accuracy: 0.7200\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6661 - accuracy: 0.5853 - val_loss: 0.6350 - val_accuracy: 0.7200\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6923 - accuracy: 0.5668 - val_loss: 0.6348 - val_accuracy: 0.7200\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6789 - accuracy: 0.6129 - val_loss: 0.6347 - val_accuracy: 0.7200\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6822 - accuracy: 0.5714 - val_loss: 0.6345 - val_accuracy: 0.7200\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6833 - accuracy: 0.5853 - val_loss: 0.6344 - val_accuracy: 0.7200\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6799 - accuracy: 0.6175 - val_loss: 0.6342 - val_accuracy: 0.7200\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6695 - accuracy: 0.5806 - val_loss: 0.6341 - val_accuracy: 0.7200\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6885 - accuracy: 0.5853 - val_loss: 0.6339 - val_accuracy: 0.7200\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6922 - accuracy: 0.5853 - val_loss: 0.6338 - val_accuracy: 0.7200\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6711 - accuracy: 0.5853 - val_loss: 0.6336 - val_accuracy: 0.7200\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6787 - accuracy: 0.5945 - val_loss: 0.6335 - val_accuracy: 0.7200\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6716 - accuracy: 0.5760 - val_loss: 0.6333 - val_accuracy: 0.7600\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6653 - accuracy: 0.6221 - val_loss: 0.6332 - val_accuracy: 0.7600\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6832 - accuracy: 0.5806 - val_loss: 0.6330 - val_accuracy: 0.7600\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6801 - accuracy: 0.5899 - val_loss: 0.6329 - val_accuracy: 0.7600\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6826 - accuracy: 0.5622 - val_loss: 0.6327 - val_accuracy: 0.7600\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6790 - accuracy: 0.5806 - val_loss: 0.6326 - val_accuracy: 0.7600\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6658 - accuracy: 0.6083 - val_loss: 0.6324 - val_accuracy: 0.7600\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6857 - accuracy: 0.5760 - val_loss: 0.6323 - val_accuracy: 0.7600\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6744 - accuracy: 0.5853 - val_loss: 0.6321 - val_accuracy: 0.7600\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6618 - accuracy: 0.6037 - val_loss: 0.6320 - val_accuracy: 0.7600\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6842 - accuracy: 0.5668 - val_loss: 0.6318 - val_accuracy: 0.7600\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6856 - accuracy: 0.5668 - val_loss: 0.6317 - val_accuracy: 0.7600\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6834 - accuracy: 0.5991 - val_loss: 0.6315 - val_accuracy: 0.7600\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6729 - accuracy: 0.5991 - val_loss: 0.6314 - val_accuracy: 0.7600\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6639 - accuracy: 0.6037 - val_loss: 0.6312 - val_accuracy: 0.7600\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6899 - accuracy: 0.5760 - val_loss: 0.6311 - val_accuracy: 0.7600\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6844 - accuracy: 0.6175 - val_loss: 0.6309 - val_accuracy: 0.7600\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6776 - accuracy: 0.5484 - val_loss: 0.6308 - val_accuracy: 0.7600\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6797 - accuracy: 0.5853 - val_loss: 0.6306 - val_accuracy: 0.7600\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6889 - accuracy: 0.5668 - val_loss: 0.6305 - val_accuracy: 0.7600\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6676 - accuracy: 0.6129 - val_loss: 0.6303 - val_accuracy: 0.7600\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6879 - accuracy: 0.5945 - val_loss: 0.6302 - val_accuracy: 0.7600\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6887 - accuracy: 0.5530 - val_loss: 0.6300 - val_accuracy: 0.7600\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6766 - accuracy: 0.5899 - val_loss: 0.6299 - val_accuracy: 0.7600\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6686 - accuracy: 0.6129 - val_loss: 0.6297 - val_accuracy: 0.7600\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6645 - accuracy: 0.5899 - val_loss: 0.6296 - val_accuracy: 0.7600\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6665 - accuracy: 0.6037 - val_loss: 0.6294 - val_accuracy: 0.7600\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6797 - accuracy: 0.5853 - val_loss: 0.6293 - val_accuracy: 0.7600\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6617 - accuracy: 0.6313 - val_loss: 0.6292 - val_accuracy: 0.7600\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6731 - accuracy: 0.5806 - val_loss: 0.6290 - val_accuracy: 0.7600\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6788 - accuracy: 0.5806 - val_loss: 0.6289 - val_accuracy: 0.7600\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6752 - accuracy: 0.5622 - val_loss: 0.6287 - val_accuracy: 0.7600\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6648 - accuracy: 0.6037 - val_loss: 0.6286 - val_accuracy: 0.7600\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6654 - accuracy: 0.5899 - val_loss: 0.6284 - val_accuracy: 0.7600\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6718 - accuracy: 0.6221 - val_loss: 0.6283 - val_accuracy: 0.7600\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6771 - accuracy: 0.5899 - val_loss: 0.6281 - val_accuracy: 0.7600\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6760 - accuracy: 0.6037 - val_loss: 0.6280 - val_accuracy: 0.7600\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6711 - accuracy: 0.5714 - val_loss: 0.6278 - val_accuracy: 0.7600\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6827 - accuracy: 0.5484 - val_loss: 0.6277 - val_accuracy: 0.7600\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6784 - accuracy: 0.5714 - val_loss: 0.6275 - val_accuracy: 0.7600\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6630 - accuracy: 0.6129 - val_loss: 0.6274 - val_accuracy: 0.7600\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6768 - accuracy: 0.5853 - val_loss: 0.6272 - val_accuracy: 0.7600\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6727 - accuracy: 0.5853 - val_loss: 0.6271 - val_accuracy: 0.7600\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6630 - accuracy: 0.6221 - val_loss: 0.6269 - val_accuracy: 0.8000\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6648 - accuracy: 0.5899 - val_loss: 0.6268 - val_accuracy: 0.8000\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6674 - accuracy: 0.6083 - val_loss: 0.6266 - val_accuracy: 0.8000\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6709 - accuracy: 0.5991 - val_loss: 0.6264 - val_accuracy: 0.8000\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6534 - accuracy: 0.6037 - val_loss: 0.6263 - val_accuracy: 0.8000\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6705 - accuracy: 0.5991 - val_loss: 0.6261 - val_accuracy: 0.8000\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6650 - accuracy: 0.6037 - val_loss: 0.6260 - val_accuracy: 0.8000\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6847 - accuracy: 0.5622 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6691 - accuracy: 0.5945 - val_loss: 0.6257 - val_accuracy: 0.8000\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6708 - accuracy: 0.5991 - val_loss: 0.6255 - val_accuracy: 0.8000\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6734 - accuracy: 0.6083 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6715 - accuracy: 0.6175 - val_loss: 0.6252 - val_accuracy: 0.8000\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6661 - accuracy: 0.5899 - val_loss: 0.6251 - val_accuracy: 0.8000\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6689 - accuracy: 0.5991 - val_loss: 0.6249 - val_accuracy: 0.8000\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6580 - accuracy: 0.6406 - val_loss: 0.6248 - val_accuracy: 0.8000\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6766 - accuracy: 0.5760 - val_loss: 0.6246 - val_accuracy: 0.8000\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6663 - accuracy: 0.5760 - val_loss: 0.6245 - val_accuracy: 0.8000\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6686 - accuracy: 0.5668 - val_loss: 0.6243 - val_accuracy: 0.8000\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6605 - accuracy: 0.6359 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6673 - accuracy: 0.5991 - val_loss: 0.6240 - val_accuracy: 0.8000\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6630 - accuracy: 0.6267 - val_loss: 0.6238 - val_accuracy: 0.8000\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6667 - accuracy: 0.6083 - val_loss: 0.6237 - val_accuracy: 0.8000\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6709 - accuracy: 0.6129 - val_loss: 0.6235 - val_accuracy: 0.8000\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6852 - accuracy: 0.5945 - val_loss: 0.6234 - val_accuracy: 0.8000\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6455 - accuracy: 0.6544 - val_loss: 0.6232 - val_accuracy: 0.8000\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6497 - accuracy: 0.6406 - val_loss: 0.6231 - val_accuracy: 0.8000\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6631 - accuracy: 0.6313 - val_loss: 0.6229 - val_accuracy: 0.8000\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6840 - accuracy: 0.5760 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6559 - accuracy: 0.6359 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6594 - accuracy: 0.6175 - val_loss: 0.6225 - val_accuracy: 0.8000\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6608 - accuracy: 0.6359 - val_loss: 0.6223 - val_accuracy: 0.8000\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6678 - accuracy: 0.5991 - val_loss: 0.6222 - val_accuracy: 0.8000\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6894 - accuracy: 0.5668 - val_loss: 0.6220 - val_accuracy: 0.8400\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6515 - accuracy: 0.6313 - val_loss: 0.6219 - val_accuracy: 0.8400\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6644 - accuracy: 0.5853 - val_loss: 0.6217 - val_accuracy: 0.8400\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6506 - accuracy: 0.6221 - val_loss: 0.6216 - val_accuracy: 0.8400\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6703 - accuracy: 0.5806 - val_loss: 0.6214 - val_accuracy: 0.8400\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6727 - accuracy: 0.5853 - val_loss: 0.6213 - val_accuracy: 0.8400\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6665 - accuracy: 0.6129 - val_loss: 0.6211 - val_accuracy: 0.8400\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6635 - accuracy: 0.5530 - val_loss: 0.6210 - val_accuracy: 0.8400\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6584 - accuracy: 0.6175 - val_loss: 0.6208 - val_accuracy: 0.8400\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6670 - accuracy: 0.6129 - val_loss: 0.6207 - val_accuracy: 0.8400\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6729 - accuracy: 0.6359 - val_loss: 0.6205 - val_accuracy: 0.8400\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6599 - accuracy: 0.6359 - val_loss: 0.6204 - val_accuracy: 0.8400\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6773 - accuracy: 0.6175 - val_loss: 0.6202 - val_accuracy: 0.8400\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6637 - accuracy: 0.6175 - val_loss: 0.6201 - val_accuracy: 0.8400\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6671 - accuracy: 0.6267 - val_loss: 0.6199 - val_accuracy: 0.8400\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6581 - accuracy: 0.6221 - val_loss: 0.6198 - val_accuracy: 0.8400\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6716 - accuracy: 0.6037 - val_loss: 0.6196 - val_accuracy: 0.8400\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6670 - accuracy: 0.5991 - val_loss: 0.6195 - val_accuracy: 0.8400\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6556 - accuracy: 0.5991 - val_loss: 0.6193 - val_accuracy: 0.8400\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6684 - accuracy: 0.5714 - val_loss: 0.6192 - val_accuracy: 0.8400\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6511 - accuracy: 0.6313 - val_loss: 0.6190 - val_accuracy: 0.8400\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6522 - accuracy: 0.6636 - val_loss: 0.6188 - val_accuracy: 0.8400\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6656 - accuracy: 0.6175 - val_loss: 0.6187 - val_accuracy: 0.8400\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6609 - accuracy: 0.5714 - val_loss: 0.6185 - val_accuracy: 0.8400\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6618 - accuracy: 0.5991 - val_loss: 0.6184 - val_accuracy: 0.8400\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6633 - accuracy: 0.6359 - val_loss: 0.6182 - val_accuracy: 0.8400\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6596 - accuracy: 0.6359 - val_loss: 0.6181 - val_accuracy: 0.8400\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6652 - accuracy: 0.6129 - val_loss: 0.6179 - val_accuracy: 0.8400\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6749 - accuracy: 0.6175 - val_loss: 0.6178 - val_accuracy: 0.8400\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6543 - accuracy: 0.6313 - val_loss: 0.6176 - val_accuracy: 0.8400\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6679 - accuracy: 0.5668 - val_loss: 0.6175 - val_accuracy: 0.8400\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6563 - accuracy: 0.6083 - val_loss: 0.6173 - val_accuracy: 0.8400\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6635 - accuracy: 0.6129 - val_loss: 0.6172 - val_accuracy: 0.8400\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6614 - accuracy: 0.6083 - val_loss: 0.6170 - val_accuracy: 0.8400\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6750 - accuracy: 0.5806 - val_loss: 0.6169 - val_accuracy: 0.8400\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6653 - accuracy: 0.6359 - val_loss: 0.6167 - val_accuracy: 0.8400\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6644 - accuracy: 0.5945 - val_loss: 0.6166 - val_accuracy: 0.8400\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6611 - accuracy: 0.5899 - val_loss: 0.6164 - val_accuracy: 0.8400\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6636 - accuracy: 0.5760 - val_loss: 0.6163 - val_accuracy: 0.8400\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6640 - accuracy: 0.6037 - val_loss: 0.6161 - val_accuracy: 0.8400\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6576 - accuracy: 0.6037 - val_loss: 0.6159 - val_accuracy: 0.8400\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6740 - accuracy: 0.5991 - val_loss: 0.6158 - val_accuracy: 0.8400\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6556 - accuracy: 0.6313 - val_loss: 0.6156 - val_accuracy: 0.8400\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6648 - accuracy: 0.6037 - val_loss: 0.6155 - val_accuracy: 0.8400\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6517 - accuracy: 0.6129 - val_loss: 0.6153 - val_accuracy: 0.8400\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6633 - accuracy: 0.5991 - val_loss: 0.6152 - val_accuracy: 0.8400\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6565 - accuracy: 0.6498 - val_loss: 0.6150 - val_accuracy: 0.8400\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6719 - accuracy: 0.5899 - val_loss: 0.6149 - val_accuracy: 0.8400\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6657 - accuracy: 0.6175 - val_loss: 0.6147 - val_accuracy: 0.8400\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6705 - accuracy: 0.5991 - val_loss: 0.6146 - val_accuracy: 0.8400\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6578 - accuracy: 0.6129 - val_loss: 0.6144 - val_accuracy: 0.8400\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6671 - accuracy: 0.6037 - val_loss: 0.6143 - val_accuracy: 0.8400\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6565 - accuracy: 0.6129 - val_loss: 0.6141 - val_accuracy: 0.8400\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6621 - accuracy: 0.6221 - val_loss: 0.6140 - val_accuracy: 0.8400\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6436 - accuracy: 0.6406 - val_loss: 0.6138 - val_accuracy: 0.8400\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6628 - accuracy: 0.5668 - val_loss: 0.6137 - val_accuracy: 0.8400\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6579 - accuracy: 0.5853 - val_loss: 0.6135 - val_accuracy: 0.8400\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6651 - accuracy: 0.5945 - val_loss: 0.6134 - val_accuracy: 0.8400\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6682 - accuracy: 0.6175 - val_loss: 0.6132 - val_accuracy: 0.8400\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6709 - accuracy: 0.5714 - val_loss: 0.6131 - val_accuracy: 0.8400\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6647 - accuracy: 0.6037 - val_loss: 0.6129 - val_accuracy: 0.8400\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6435 - accuracy: 0.6636 - val_loss: 0.6128 - val_accuracy: 0.8400\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6576 - accuracy: 0.6221 - val_loss: 0.6126 - val_accuracy: 0.8400\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6528 - accuracy: 0.5945 - val_loss: 0.6125 - val_accuracy: 0.8400\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6692 - accuracy: 0.5668 - val_loss: 0.6123 - val_accuracy: 0.8400\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6552 - accuracy: 0.6359 - val_loss: 0.6122 - val_accuracy: 0.8400\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6489 - accuracy: 0.6175 - val_loss: 0.6120 - val_accuracy: 0.8400\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6683 - accuracy: 0.5899 - val_loss: 0.6119 - val_accuracy: 0.8400\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6422 - accuracy: 0.6452 - val_loss: 0.6117 - val_accuracy: 0.8400\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6526 - accuracy: 0.6498 - val_loss: 0.6116 - val_accuracy: 0.8400\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6518 - accuracy: 0.6037 - val_loss: 0.6114 - val_accuracy: 0.8400\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6468 - accuracy: 0.6498 - val_loss: 0.6113 - val_accuracy: 0.8400\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6350 - accuracy: 0.6636 - val_loss: 0.6111 - val_accuracy: 0.8400\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6654 - accuracy: 0.6221 - val_loss: 0.6110 - val_accuracy: 0.8400\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6643 - accuracy: 0.6498 - val_loss: 0.6108 - val_accuracy: 0.8400\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6540 - accuracy: 0.6544 - val_loss: 0.6106 - val_accuracy: 0.8400\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6667 - accuracy: 0.6129 - val_loss: 0.6105 - val_accuracy: 0.8400\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6522 - accuracy: 0.6313 - val_loss: 0.6103 - val_accuracy: 0.8400\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6493 - accuracy: 0.6452 - val_loss: 0.6102 - val_accuracy: 0.8400\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6631 - accuracy: 0.6083 - val_loss: 0.6100 - val_accuracy: 0.8400\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6657 - accuracy: 0.6083 - val_loss: 0.6099 - val_accuracy: 0.8400\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6409 - accuracy: 0.6406 - val_loss: 0.6097 - val_accuracy: 0.8400\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6409 - accuracy: 0.6221 - val_loss: 0.6095 - val_accuracy: 0.8400\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6535 - accuracy: 0.6221 - val_loss: 0.6094 - val_accuracy: 0.8400\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6527 - accuracy: 0.6175 - val_loss: 0.6092 - val_accuracy: 0.8400\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6513 - accuracy: 0.6452 - val_loss: 0.6091 - val_accuracy: 0.8800\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6543 - accuracy: 0.6267 - val_loss: 0.6089 - val_accuracy: 0.8800\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6625 - accuracy: 0.6129 - val_loss: 0.6088 - val_accuracy: 0.8800\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6558 - accuracy: 0.6037 - val_loss: 0.6086 - val_accuracy: 0.8800\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6559 - accuracy: 0.6313 - val_loss: 0.6085 - val_accuracy: 0.8800\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6495 - accuracy: 0.6452 - val_loss: 0.6083 - val_accuracy: 0.8800\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6514 - accuracy: 0.6313 - val_loss: 0.6081 - val_accuracy: 0.8800\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6445 - accuracy: 0.6682 - val_loss: 0.6080 - val_accuracy: 0.8800\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6356 - accuracy: 0.6774 - val_loss: 0.6078 - val_accuracy: 0.8800\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6527 - accuracy: 0.5991 - val_loss: 0.6077 - val_accuracy: 0.8800\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6595 - accuracy: 0.6037 - val_loss: 0.6075 - val_accuracy: 0.8800\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6601 - accuracy: 0.5899 - val_loss: 0.6074 - val_accuracy: 0.8800\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6489 - accuracy: 0.6636 - val_loss: 0.6072 - val_accuracy: 0.8800\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6518 - accuracy: 0.6267 - val_loss: 0.6071 - val_accuracy: 0.8800\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6489 - accuracy: 0.6774 - val_loss: 0.6069 - val_accuracy: 0.8800\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6549 - accuracy: 0.6406 - val_loss: 0.6067 - val_accuracy: 0.8800\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6407 - accuracy: 0.6590 - val_loss: 0.6066 - val_accuracy: 0.8800\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6656 - accuracy: 0.6129 - val_loss: 0.6064 - val_accuracy: 0.8800\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6501 - accuracy: 0.6359 - val_loss: 0.6063 - val_accuracy: 0.8800\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6504 - accuracy: 0.6406 - val_loss: 0.6061 - val_accuracy: 0.8800\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6554 - accuracy: 0.6175 - val_loss: 0.6060 - val_accuracy: 0.8800\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6345 - accuracy: 0.6774 - val_loss: 0.6058 - val_accuracy: 0.8800\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6546 - accuracy: 0.6221 - val_loss: 0.6057 - val_accuracy: 0.8800\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6408 - accuracy: 0.6498 - val_loss: 0.6055 - val_accuracy: 0.8800\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6497 - accuracy: 0.6359 - val_loss: 0.6053 - val_accuracy: 0.8800\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6483 - accuracy: 0.6313 - val_loss: 0.6052 - val_accuracy: 0.8800\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6528 - accuracy: 0.6175 - val_loss: 0.6050 - val_accuracy: 0.8800\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6604 - accuracy: 0.6221 - val_loss: 0.6049 - val_accuracy: 0.8800\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6397 - accuracy: 0.6452 - val_loss: 0.6047 - val_accuracy: 0.8800\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6533 - accuracy: 0.6129 - val_loss: 0.6045 - val_accuracy: 0.8800\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6503 - accuracy: 0.6175 - val_loss: 0.6044 - val_accuracy: 0.8800\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6463 - accuracy: 0.6728 - val_loss: 0.6042 - val_accuracy: 0.8800\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6383 - accuracy: 0.6912 - val_loss: 0.6040 - val_accuracy: 0.8800\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6411 - accuracy: 0.6359 - val_loss: 0.6039 - val_accuracy: 0.8800\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6437 - accuracy: 0.6452 - val_loss: 0.6037 - val_accuracy: 0.8800\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6419 - accuracy: 0.6221 - val_loss: 0.6036 - val_accuracy: 0.8800\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6495 - accuracy: 0.6221 - val_loss: 0.6034 - val_accuracy: 0.8800\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6456 - accuracy: 0.6636 - val_loss: 0.6032 - val_accuracy: 0.8800\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6460 - accuracy: 0.6636 - val_loss: 0.6031 - val_accuracy: 0.8800\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6448 - accuracy: 0.6175 - val_loss: 0.6029 - val_accuracy: 0.8800\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6488 - accuracy: 0.5945 - val_loss: 0.6028 - val_accuracy: 0.8800\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6412 - accuracy: 0.6267 - val_loss: 0.6026 - val_accuracy: 0.8800\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6365 - accuracy: 0.6406 - val_loss: 0.6025 - val_accuracy: 0.8800\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6506 - accuracy: 0.6452 - val_loss: 0.6023 - val_accuracy: 0.8800\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6314 - accuracy: 0.6544 - val_loss: 0.6022 - val_accuracy: 0.8800\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6400 - accuracy: 0.6498 - val_loss: 0.6020 - val_accuracy: 0.8800\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6414 - accuracy: 0.6267 - val_loss: 0.6018 - val_accuracy: 0.8800\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6462 - accuracy: 0.6682 - val_loss: 0.6017 - val_accuracy: 0.8800\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6451 - accuracy: 0.6452 - val_loss: 0.6015 - val_accuracy: 0.8800\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6595 - accuracy: 0.5853 - val_loss: 0.6014 - val_accuracy: 0.8800\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6519 - accuracy: 0.6221 - val_loss: 0.6012 - val_accuracy: 0.8800\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6415 - accuracy: 0.6728 - val_loss: 0.6011 - val_accuracy: 0.8800\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6361 - accuracy: 0.6359 - val_loss: 0.6009 - val_accuracy: 0.8800\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6447 - accuracy: 0.6728 - val_loss: 0.6008 - val_accuracy: 0.8800\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6338 - accuracy: 0.6313 - val_loss: 0.6006 - val_accuracy: 0.8800\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6340 - accuracy: 0.6452 - val_loss: 0.6004 - val_accuracy: 0.8800\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6392 - accuracy: 0.6544 - val_loss: 0.6003 - val_accuracy: 0.8800\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6421 - accuracy: 0.6498 - val_loss: 0.6001 - val_accuracy: 0.8800\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6447 - accuracy: 0.6083 - val_loss: 0.6000 - val_accuracy: 0.8800\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6374 - accuracy: 0.6221 - val_loss: 0.5998 - val_accuracy: 0.8800\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6355 - accuracy: 0.6912 - val_loss: 0.5997 - val_accuracy: 0.8800\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6347 - accuracy: 0.6866 - val_loss: 0.5995 - val_accuracy: 0.8800\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.5994 - val_accuracy: 0.8800\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6282 - accuracy: 0.6498 - val_loss: 0.5992 - val_accuracy: 0.8800\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6469 - accuracy: 0.6359 - val_loss: 0.5991 - val_accuracy: 0.8800\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6427 - accuracy: 0.6267 - val_loss: 0.5989 - val_accuracy: 0.8800\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6553 - accuracy: 0.6406 - val_loss: 0.5988 - val_accuracy: 0.8800\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6477 - accuracy: 0.6406 - val_loss: 0.5986 - val_accuracy: 0.8800\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6364 - accuracy: 0.6590 - val_loss: 0.5985 - val_accuracy: 0.8800\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6510 - accuracy: 0.6498 - val_loss: 0.5983 - val_accuracy: 0.8800\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6280 - accuracy: 0.6544 - val_loss: 0.5981 - val_accuracy: 0.8800\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6491 - accuracy: 0.6544 - val_loss: 0.5980 - val_accuracy: 0.8800\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6409 - accuracy: 0.6728 - val_loss: 0.5978 - val_accuracy: 0.8800\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6461 - accuracy: 0.6406 - val_loss: 0.5977 - val_accuracy: 0.8800\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6521 - accuracy: 0.6129 - val_loss: 0.5975 - val_accuracy: 0.8800\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6308 - accuracy: 0.6682 - val_loss: 0.5973 - val_accuracy: 0.8800\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6319 - accuracy: 0.6820 - val_loss: 0.5972 - val_accuracy: 0.8800\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6391 - accuracy: 0.6267 - val_loss: 0.5970 - val_accuracy: 0.8800\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6517 - accuracy: 0.6083 - val_loss: 0.5969 - val_accuracy: 0.8800\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6453 - accuracy: 0.6359 - val_loss: 0.5967 - val_accuracy: 0.8800\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6527 - accuracy: 0.6129 - val_loss: 0.5965 - val_accuracy: 0.8800\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6397 - accuracy: 0.6498 - val_loss: 0.5964 - val_accuracy: 0.8800\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6513 - accuracy: 0.6498 - val_loss: 0.5962 - val_accuracy: 0.8800\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6434 - accuracy: 0.6498 - val_loss: 0.5960 - val_accuracy: 0.8800\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6338 - accuracy: 0.6774 - val_loss: 0.5959 - val_accuracy: 0.8800\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6363 - accuracy: 0.6682 - val_loss: 0.5957 - val_accuracy: 0.8800\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6167 - accuracy: 0.6774 - val_loss: 0.5956 - val_accuracy: 0.8800\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6343 - accuracy: 0.6590 - val_loss: 0.5954 - val_accuracy: 0.8800\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6443 - accuracy: 0.6406 - val_loss: 0.5952 - val_accuracy: 0.8800\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6410 - accuracy: 0.6452 - val_loss: 0.5951 - val_accuracy: 0.8800\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6468 - accuracy: 0.6544 - val_loss: 0.5949 - val_accuracy: 0.8800\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6466 - accuracy: 0.6544 - val_loss: 0.5947 - val_accuracy: 0.8800\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6277 - accuracy: 0.6820 - val_loss: 0.5946 - val_accuracy: 0.8800\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6290 - accuracy: 0.6313 - val_loss: 0.5944 - val_accuracy: 0.8800\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6444 - accuracy: 0.6359 - val_loss: 0.5943 - val_accuracy: 0.8800\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6657 - accuracy: 0.5899 - val_loss: 0.5941 - val_accuracy: 0.8800\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6443 - accuracy: 0.6037 - val_loss: 0.5939 - val_accuracy: 0.8800\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6309 - accuracy: 0.6544 - val_loss: 0.5938 - val_accuracy: 0.8800\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6409 - accuracy: 0.6820 - val_loss: 0.5936 - val_accuracy: 0.8800\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6513 - accuracy: 0.6313 - val_loss: 0.5934 - val_accuracy: 0.8800\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6226 - accuracy: 0.6820 - val_loss: 0.5933 - val_accuracy: 0.8800\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6271 - accuracy: 0.6959 - val_loss: 0.5931 - val_accuracy: 0.8800\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6268 - accuracy: 0.6359 - val_loss: 0.5929 - val_accuracy: 0.8800\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6360 - accuracy: 0.6544 - val_loss: 0.5928 - val_accuracy: 0.8800\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6467 - accuracy: 0.6221 - val_loss: 0.5926 - val_accuracy: 0.8800\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6384 - accuracy: 0.6544 - val_loss: 0.5924 - val_accuracy: 0.8800\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6331 - accuracy: 0.6544 - val_loss: 0.5923 - val_accuracy: 0.8800\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6341 - accuracy: 0.6406 - val_loss: 0.5921 - val_accuracy: 0.8800\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6410 - accuracy: 0.6590 - val_loss: 0.5919 - val_accuracy: 0.8800\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6200 - accuracy: 0.6452 - val_loss: 0.5918 - val_accuracy: 0.8800\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6388 - accuracy: 0.6083 - val_loss: 0.5916 - val_accuracy: 0.8800\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6456 - accuracy: 0.6359 - val_loss: 0.5914 - val_accuracy: 0.8800\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6341 - accuracy: 0.6590 - val_loss: 0.5913 - val_accuracy: 0.8800\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6436 - accuracy: 0.6498 - val_loss: 0.5911 - val_accuracy: 0.8800\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6417 - accuracy: 0.6452 - val_loss: 0.5909 - val_accuracy: 0.8800\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6412 - accuracy: 0.6774 - val_loss: 0.5908 - val_accuracy: 0.8800\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6206 - accuracy: 0.6774 - val_loss: 0.5906 - val_accuracy: 0.8800\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6414 - accuracy: 0.6636 - val_loss: 0.5904 - val_accuracy: 0.8800\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6407 - accuracy: 0.6682 - val_loss: 0.5903 - val_accuracy: 0.8800\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6217 - accuracy: 0.6959 - val_loss: 0.5901 - val_accuracy: 0.8800\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6464 - accuracy: 0.6406 - val_loss: 0.5899 - val_accuracy: 0.8800\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6345 - accuracy: 0.6728 - val_loss: 0.5898 - val_accuracy: 0.8800\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6383 - accuracy: 0.6866 - val_loss: 0.5896 - val_accuracy: 0.8800\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6400 - accuracy: 0.6175 - val_loss: 0.5894 - val_accuracy: 0.8800\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6410 - accuracy: 0.6590 - val_loss: 0.5893 - val_accuracy: 0.8800\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6340 - accuracy: 0.6359 - val_loss: 0.5891 - val_accuracy: 0.8800\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6405 - accuracy: 0.6728 - val_loss: 0.5890 - val_accuracy: 0.8800\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6502 - accuracy: 0.6498 - val_loss: 0.5888 - val_accuracy: 0.8800\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6266 - accuracy: 0.6774 - val_loss: 0.5886 - val_accuracy: 0.8800\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6338 - accuracy: 0.6544 - val_loss: 0.5885 - val_accuracy: 0.8800\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6327 - accuracy: 0.6866 - val_loss: 0.5883 - val_accuracy: 0.8800\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6392 - accuracy: 0.6636 - val_loss: 0.5882 - val_accuracy: 0.8800\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6201 - accuracy: 0.6682 - val_loss: 0.5880 - val_accuracy: 0.8800\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6356 - accuracy: 0.6636 - val_loss: 0.5879 - val_accuracy: 0.8800\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6387 - accuracy: 0.6313 - val_loss: 0.5877 - val_accuracy: 0.8800\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6367 - accuracy: 0.6636 - val_loss: 0.5875 - val_accuracy: 0.8800\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6387 - accuracy: 0.6359 - val_loss: 0.5874 - val_accuracy: 0.8800\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6330 - accuracy: 0.6728 - val_loss: 0.5872 - val_accuracy: 0.8800\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6451 - accuracy: 0.6590 - val_loss: 0.5871 - val_accuracy: 0.8800\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6292 - accuracy: 0.6590 - val_loss: 0.5869 - val_accuracy: 0.8800\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6319 - accuracy: 0.6682 - val_loss: 0.5867 - val_accuracy: 0.8800\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6258 - accuracy: 0.6682 - val_loss: 0.5866 - val_accuracy: 0.8800\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6362 - accuracy: 0.6544 - val_loss: 0.5864 - val_accuracy: 0.8400\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6454 - accuracy: 0.6175 - val_loss: 0.5863 - val_accuracy: 0.8400\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6298 - accuracy: 0.6590 - val_loss: 0.5861 - val_accuracy: 0.8400\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6380 - accuracy: 0.6636 - val_loss: 0.5859 - val_accuracy: 0.8400\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6343 - accuracy: 0.6590 - val_loss: 0.5858 - val_accuracy: 0.8400\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6304 - accuracy: 0.6498 - val_loss: 0.5856 - val_accuracy: 0.8400\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6301 - accuracy: 0.6544 - val_loss: 0.5855 - val_accuracy: 0.8400\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6373 - accuracy: 0.6590 - val_loss: 0.5853 - val_accuracy: 0.8400\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6255 - accuracy: 0.7051 - val_loss: 0.5851 - val_accuracy: 0.8400\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6332 - accuracy: 0.6728 - val_loss: 0.5850 - val_accuracy: 0.8400\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6259 - accuracy: 0.6959 - val_loss: 0.5848 - val_accuracy: 0.8400\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6212 - accuracy: 0.6820 - val_loss: 0.5846 - val_accuracy: 0.8400\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6372 - accuracy: 0.6498 - val_loss: 0.5845 - val_accuracy: 0.8400\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6308 - accuracy: 0.6682 - val_loss: 0.5843 - val_accuracy: 0.8400\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6317 - accuracy: 0.6452 - val_loss: 0.5841 - val_accuracy: 0.8400\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6267 - accuracy: 0.6866 - val_loss: 0.5840 - val_accuracy: 0.8400\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6247 - accuracy: 0.6912 - val_loss: 0.5838 - val_accuracy: 0.8400\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6308 - accuracy: 0.6359 - val_loss: 0.5836 - val_accuracy: 0.8400\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6396 - accuracy: 0.6590 - val_loss: 0.5835 - val_accuracy: 0.8400\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6231 - accuracy: 0.6682 - val_loss: 0.5833 - val_accuracy: 0.8400\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6233 - accuracy: 0.6544 - val_loss: 0.5832 - val_accuracy: 0.8400\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6180 - accuracy: 0.6866 - val_loss: 0.5830 - val_accuracy: 0.8400\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6190 - accuracy: 0.7097 - val_loss: 0.5828 - val_accuracy: 0.8400\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6285 - accuracy: 0.6544 - val_loss: 0.5827 - val_accuracy: 0.8400\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6225 - accuracy: 0.6820 - val_loss: 0.5825 - val_accuracy: 0.8400\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6316 - accuracy: 0.6636 - val_loss: 0.5823 - val_accuracy: 0.8400\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6169 - accuracy: 0.7005 - val_loss: 0.5821 - val_accuracy: 0.8400\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6379 - accuracy: 0.6267 - val_loss: 0.5820 - val_accuracy: 0.8400\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6240 - accuracy: 0.6406 - val_loss: 0.5818 - val_accuracy: 0.8400\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6217 - accuracy: 0.6774 - val_loss: 0.5816 - val_accuracy: 0.8400\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6289 - accuracy: 0.6544 - val_loss: 0.5815 - val_accuracy: 0.8400\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6446 - accuracy: 0.6406 - val_loss: 0.5813 - val_accuracy: 0.8400\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6316 - accuracy: 0.6498 - val_loss: 0.5811 - val_accuracy: 0.8400\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6168 - accuracy: 0.6959 - val_loss: 0.5810 - val_accuracy: 0.8400\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6305 - accuracy: 0.6728 - val_loss: 0.5808 - val_accuracy: 0.8400\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6244 - accuracy: 0.6359 - val_loss: 0.5806 - val_accuracy: 0.8400\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6125 - accuracy: 0.7189 - val_loss: 0.5805 - val_accuracy: 0.8400\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6475 - accuracy: 0.6544 - val_loss: 0.5803 - val_accuracy: 0.8400\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6293 - accuracy: 0.6682 - val_loss: 0.5801 - val_accuracy: 0.8400\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6139 - accuracy: 0.6866 - val_loss: 0.5799 - val_accuracy: 0.8400\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6311 - accuracy: 0.6728 - val_loss: 0.5798 - val_accuracy: 0.8400\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6307 - accuracy: 0.6221 - val_loss: 0.5796 - val_accuracy: 0.8400\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6297 - accuracy: 0.6359 - val_loss: 0.5794 - val_accuracy: 0.8400\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6370 - accuracy: 0.6406 - val_loss: 0.5792 - val_accuracy: 0.8400\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6178 - accuracy: 0.6820 - val_loss: 0.5791 - val_accuracy: 0.8400\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6279 - accuracy: 0.6820 - val_loss: 0.5789 - val_accuracy: 0.8400\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6237 - accuracy: 0.6728 - val_loss: 0.5787 - val_accuracy: 0.8400\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6180 - accuracy: 0.6959 - val_loss: 0.5785 - val_accuracy: 0.8400\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6296 - accuracy: 0.6590 - val_loss: 0.5784 - val_accuracy: 0.8400\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6265 - accuracy: 0.6959 - val_loss: 0.5782 - val_accuracy: 0.8400\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6275 - accuracy: 0.6820 - val_loss: 0.5780 - val_accuracy: 0.8400\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6300 - accuracy: 0.6728 - val_loss: 0.5778 - val_accuracy: 0.8400\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6454 - accuracy: 0.6406 - val_loss: 0.5777 - val_accuracy: 0.8400\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6314 - accuracy: 0.6544 - val_loss: 0.5775 - val_accuracy: 0.8400\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6318 - accuracy: 0.6406 - val_loss: 0.5773 - val_accuracy: 0.8400\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6121 - accuracy: 0.6728 - val_loss: 0.5771 - val_accuracy: 0.8400\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6304 - accuracy: 0.6774 - val_loss: 0.5770 - val_accuracy: 0.8400\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6189 - accuracy: 0.7097 - val_loss: 0.5768 - val_accuracy: 0.8400\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6374 - accuracy: 0.6959 - val_loss: 0.5766 - val_accuracy: 0.8400\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6383 - accuracy: 0.6682 - val_loss: 0.5765 - val_accuracy: 0.8400\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6397 - accuracy: 0.6636 - val_loss: 0.5763 - val_accuracy: 0.8400\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6296 - accuracy: 0.6452 - val_loss: 0.5761 - val_accuracy: 0.8400\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6299 - accuracy: 0.6452 - val_loss: 0.5759 - val_accuracy: 0.8400\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6198 - accuracy: 0.6682 - val_loss: 0.5758 - val_accuracy: 0.8400\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6407 - accuracy: 0.6313 - val_loss: 0.5756 - val_accuracy: 0.8400\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6280 - accuracy: 0.6866 - val_loss: 0.5754 - val_accuracy: 0.8400\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6106 - accuracy: 0.6959 - val_loss: 0.5753 - val_accuracy: 0.8400\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6304 - accuracy: 0.6866 - val_loss: 0.5751 - val_accuracy: 0.8400\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6197 - accuracy: 0.6959 - val_loss: 0.5749 - val_accuracy: 0.8400\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6219 - accuracy: 0.6498 - val_loss: 0.5748 - val_accuracy: 0.8400\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6190 - accuracy: 0.6820 - val_loss: 0.5746 - val_accuracy: 0.8400\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6140 - accuracy: 0.6959 - val_loss: 0.5744 - val_accuracy: 0.8400\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6333 - accuracy: 0.6590 - val_loss: 0.5743 - val_accuracy: 0.8400\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6023 - accuracy: 0.7051 - val_loss: 0.5741 - val_accuracy: 0.8400\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6135 - accuracy: 0.6774 - val_loss: 0.5739 - val_accuracy: 0.8400\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6142 - accuracy: 0.6682 - val_loss: 0.5738 - val_accuracy: 0.8400\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6164 - accuracy: 0.6682 - val_loss: 0.5736 - val_accuracy: 0.8400\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6175 - accuracy: 0.6636 - val_loss: 0.5734 - val_accuracy: 0.8400\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6196 - accuracy: 0.6728 - val_loss: 0.5733 - val_accuracy: 0.8400\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6130 - accuracy: 0.7051 - val_loss: 0.5731 - val_accuracy: 0.8400\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6173 - accuracy: 0.6682 - val_loss: 0.5729 - val_accuracy: 0.8400\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6284 - accuracy: 0.6728 - val_loss: 0.5727 - val_accuracy: 0.8400\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6297 - accuracy: 0.6359 - val_loss: 0.5726 - val_accuracy: 0.8400\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6062 - accuracy: 0.7051 - val_loss: 0.5724 - val_accuracy: 0.8400\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6134 - accuracy: 0.7327 - val_loss: 0.5722 - val_accuracy: 0.8400\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6183 - accuracy: 0.6820 - val_loss: 0.5721 - val_accuracy: 0.8400\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6216 - accuracy: 0.6774 - val_loss: 0.5719 - val_accuracy: 0.8400\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6115 - accuracy: 0.6774 - val_loss: 0.5717 - val_accuracy: 0.8400\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6139 - accuracy: 0.6820 - val_loss: 0.5715 - val_accuracy: 0.8400\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6065 - accuracy: 0.7143 - val_loss: 0.5714 - val_accuracy: 0.8400\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6187 - accuracy: 0.6866 - val_loss: 0.5712 - val_accuracy: 0.8400\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6248 - accuracy: 0.6774 - val_loss: 0.5710 - val_accuracy: 0.8400\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6058 - accuracy: 0.6959 - val_loss: 0.5708 - val_accuracy: 0.8400\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6222 - accuracy: 0.6590 - val_loss: 0.5707 - val_accuracy: 0.8400\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6190 - accuracy: 0.6682 - val_loss: 0.5705 - val_accuracy: 0.8400\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6189 - accuracy: 0.7005 - val_loss: 0.5703 - val_accuracy: 0.8400\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6175 - accuracy: 0.6820 - val_loss: 0.5702 - val_accuracy: 0.8400\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6198 - accuracy: 0.6590 - val_loss: 0.5700 - val_accuracy: 0.8400\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6218 - accuracy: 0.7005 - val_loss: 0.5698 - val_accuracy: 0.8400\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6161 - accuracy: 0.6682 - val_loss: 0.5696 - val_accuracy: 0.8400\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5886 - accuracy: 0.7281 - val_loss: 0.5695 - val_accuracy: 0.8400\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5995 - accuracy: 0.7558 - val_loss: 0.5693 - val_accuracy: 0.8400\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6153 - accuracy: 0.6774 - val_loss: 0.5691 - val_accuracy: 0.8400\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6091 - accuracy: 0.6682 - val_loss: 0.5689 - val_accuracy: 0.8400\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6123 - accuracy: 0.6912 - val_loss: 0.5687 - val_accuracy: 0.8400\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6022 - accuracy: 0.7281 - val_loss: 0.5686 - val_accuracy: 0.8400\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6056 - accuracy: 0.7097 - val_loss: 0.5684 - val_accuracy: 0.8400\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6117 - accuracy: 0.6820 - val_loss: 0.5682 - val_accuracy: 0.8400\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6128 - accuracy: 0.7005 - val_loss: 0.5680 - val_accuracy: 0.8400\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6177 - accuracy: 0.6774 - val_loss: 0.5678 - val_accuracy: 0.8400\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6117 - accuracy: 0.6866 - val_loss: 0.5677 - val_accuracy: 0.8400\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6261 - accuracy: 0.6728 - val_loss: 0.5675 - val_accuracy: 0.8400\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6088 - accuracy: 0.6774 - val_loss: 0.5673 - val_accuracy: 0.8400\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6327 - accuracy: 0.6590 - val_loss: 0.5671 - val_accuracy: 0.8400\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6106 - accuracy: 0.7281 - val_loss: 0.5670 - val_accuracy: 0.8400\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6006 - accuracy: 0.7005 - val_loss: 0.5668 - val_accuracy: 0.8400\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6248 - accuracy: 0.6728 - val_loss: 0.5666 - val_accuracy: 0.8400\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5973 - accuracy: 0.6959 - val_loss: 0.5665 - val_accuracy: 0.8400\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6150 - accuracy: 0.6866 - val_loss: 0.5663 - val_accuracy: 0.8400\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6083 - accuracy: 0.6728 - val_loss: 0.5661 - val_accuracy: 0.8400\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6268 - accuracy: 0.6636 - val_loss: 0.5659 - val_accuracy: 0.8400\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6048 - accuracy: 0.7097 - val_loss: 0.5658 - val_accuracy: 0.8400\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6087 - accuracy: 0.7051 - val_loss: 0.5656 - val_accuracy: 0.8400\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6039 - accuracy: 0.7143 - val_loss: 0.5654 - val_accuracy: 0.8400\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6145 - accuracy: 0.7097 - val_loss: 0.5653 - val_accuracy: 0.8400\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5974 - accuracy: 0.7419 - val_loss: 0.5651 - val_accuracy: 0.8400\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6113 - accuracy: 0.6959 - val_loss: 0.5649 - val_accuracy: 0.8400\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6241 - accuracy: 0.6820 - val_loss: 0.5647 - val_accuracy: 0.8400\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6108 - accuracy: 0.7097 - val_loss: 0.5646 - val_accuracy: 0.8400\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6166 - accuracy: 0.6774 - val_loss: 0.5644 - val_accuracy: 0.8400\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6061 - accuracy: 0.6866 - val_loss: 0.5642 - val_accuracy: 0.8400\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6264 - accuracy: 0.6590 - val_loss: 0.5641 - val_accuracy: 0.8400\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5939 - accuracy: 0.7235 - val_loss: 0.5639 - val_accuracy: 0.8400\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6041 - accuracy: 0.7005 - val_loss: 0.5637 - val_accuracy: 0.8400\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6036 - accuracy: 0.6912 - val_loss: 0.5636 - val_accuracy: 0.8400\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6243 - accuracy: 0.6544 - val_loss: 0.5634 - val_accuracy: 0.8400\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6140 - accuracy: 0.7189 - val_loss: 0.5632 - val_accuracy: 0.8400\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6089 - accuracy: 0.7281 - val_loss: 0.5630 - val_accuracy: 0.8400\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6139 - accuracy: 0.6636 - val_loss: 0.5629 - val_accuracy: 0.8400\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6056 - accuracy: 0.7327 - val_loss: 0.5627 - val_accuracy: 0.8400\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6142 - accuracy: 0.7051 - val_loss: 0.5625 - val_accuracy: 0.8400\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6165 - accuracy: 0.6959 - val_loss: 0.5624 - val_accuracy: 0.8400\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6079 - accuracy: 0.6820 - val_loss: 0.5622 - val_accuracy: 0.8400\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6107 - accuracy: 0.7005 - val_loss: 0.5620 - val_accuracy: 0.8400\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5926 - accuracy: 0.7097 - val_loss: 0.5618 - val_accuracy: 0.8400\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6056 - accuracy: 0.7097 - val_loss: 0.5616 - val_accuracy: 0.8400\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6108 - accuracy: 0.7235 - val_loss: 0.5615 - val_accuracy: 0.8400\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5974 - accuracy: 0.7051 - val_loss: 0.5613 - val_accuracy: 0.8400\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6029 - accuracy: 0.6682 - val_loss: 0.5611 - val_accuracy: 0.8400\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5940 - accuracy: 0.7097 - val_loss: 0.5609 - val_accuracy: 0.8400\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6100 - accuracy: 0.6820 - val_loss: 0.5607 - val_accuracy: 0.8400\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6008 - accuracy: 0.7005 - val_loss: 0.5606 - val_accuracy: 0.8400\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5983 - accuracy: 0.7281 - val_loss: 0.5604 - val_accuracy: 0.8400\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6209 - accuracy: 0.6498 - val_loss: 0.5602 - val_accuracy: 0.8400\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5999 - accuracy: 0.7373 - val_loss: 0.5600 - val_accuracy: 0.8400\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6133 - accuracy: 0.6912 - val_loss: 0.5598 - val_accuracy: 0.8400\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5965 - accuracy: 0.7189 - val_loss: 0.5597 - val_accuracy: 0.8400\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6025 - accuracy: 0.7281 - val_loss: 0.5595 - val_accuracy: 0.8400\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6148 - accuracy: 0.6866 - val_loss: 0.5593 - val_accuracy: 0.8400\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6079 - accuracy: 0.6866 - val_loss: 0.5591 - val_accuracy: 0.8400\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6067 - accuracy: 0.6774 - val_loss: 0.5590 - val_accuracy: 0.8400\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6038 - accuracy: 0.6866 - val_loss: 0.5588 - val_accuracy: 0.8400\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6139 - accuracy: 0.6774 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6118 - accuracy: 0.7235 - val_loss: 0.5584 - val_accuracy: 0.8000\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6015 - accuracy: 0.6912 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6019 - accuracy: 0.6866 - val_loss: 0.5580 - val_accuracy: 0.8000\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6018 - accuracy: 0.7189 - val_loss: 0.5579 - val_accuracy: 0.8000\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5938 - accuracy: 0.7512 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5978 - accuracy: 0.7189 - val_loss: 0.5575 - val_accuracy: 0.8000\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6017 - accuracy: 0.7327 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5951 - accuracy: 0.6912 - val_loss: 0.5571 - val_accuracy: 0.8000\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5997 - accuracy: 0.7327 - val_loss: 0.5569 - val_accuracy: 0.8000\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5901 - accuracy: 0.6959 - val_loss: 0.5567 - val_accuracy: 0.8000\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6083 - accuracy: 0.6912 - val_loss: 0.5565 - val_accuracy: 0.8000\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6133 - accuracy: 0.6590 - val_loss: 0.5563 - val_accuracy: 0.8000\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6085 - accuracy: 0.7097 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5989 - accuracy: 0.7097 - val_loss: 0.5559 - val_accuracy: 0.8000\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6009 - accuracy: 0.6912 - val_loss: 0.5558 - val_accuracy: 0.8000\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6195 - accuracy: 0.6820 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5949 - accuracy: 0.7373 - val_loss: 0.5554 - val_accuracy: 0.8000\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6068 - accuracy: 0.7097 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6159 - accuracy: 0.6866 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6043 - accuracy: 0.7281 - val_loss: 0.5548 - val_accuracy: 0.8000\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5930 - accuracy: 0.7189 - val_loss: 0.5546 - val_accuracy: 0.8000\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6053 - accuracy: 0.7005 - val_loss: 0.5544 - val_accuracy: 0.8000\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6038 - accuracy: 0.7097 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5969 - accuracy: 0.7097 - val_loss: 0.5541 - val_accuracy: 0.8000\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6076 - accuracy: 0.6912 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5918 - accuracy: 0.6959 - val_loss: 0.5537 - val_accuracy: 0.8000\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6115 - accuracy: 0.6959 - val_loss: 0.5535 - val_accuracy: 0.8000\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5967 - accuracy: 0.7051 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6013 - accuracy: 0.7512 - val_loss: 0.5531 - val_accuracy: 0.8000\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5829 - accuracy: 0.7604 - val_loss: 0.5529 - val_accuracy: 0.8000\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5963 - accuracy: 0.7005 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5988 - accuracy: 0.7097 - val_loss: 0.5525 - val_accuracy: 0.8000\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6178 - accuracy: 0.6866 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5883 - accuracy: 0.7512 - val_loss: 0.5521 - val_accuracy: 0.8000\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5868 - accuracy: 0.7512 - val_loss: 0.5519 - val_accuracy: 0.8000\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5969 - accuracy: 0.7097 - val_loss: 0.5517 - val_accuracy: 0.8400\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5951 - accuracy: 0.6820 - val_loss: 0.5515 - val_accuracy: 0.8400\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5932 - accuracy: 0.7281 - val_loss: 0.5513 - val_accuracy: 0.8400\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6037 - accuracy: 0.7051 - val_loss: 0.5511 - val_accuracy: 0.8400\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5995 - accuracy: 0.6590 - val_loss: 0.5509 - val_accuracy: 0.8400\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5918 - accuracy: 0.7097 - val_loss: 0.5507 - val_accuracy: 0.8400\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5941 - accuracy: 0.7189 - val_loss: 0.5505 - val_accuracy: 0.8400\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6000 - accuracy: 0.7189 - val_loss: 0.5503 - val_accuracy: 0.8400\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6026 - accuracy: 0.6590 - val_loss: 0.5501 - val_accuracy: 0.8400\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6061 - accuracy: 0.6774 - val_loss: 0.5499 - val_accuracy: 0.8400\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6003 - accuracy: 0.6866 - val_loss: 0.5497 - val_accuracy: 0.8400\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6156 - accuracy: 0.6912 - val_loss: 0.5495 - val_accuracy: 0.8400\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5960 - accuracy: 0.7235 - val_loss: 0.5493 - val_accuracy: 0.8400\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6090 - accuracy: 0.7005 - val_loss: 0.5491 - val_accuracy: 0.8400\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5878 - accuracy: 0.7327 - val_loss: 0.5489 - val_accuracy: 0.8400\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5969 - accuracy: 0.7327 - val_loss: 0.5488 - val_accuracy: 0.8400\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6018 - accuracy: 0.6912 - val_loss: 0.5486 - val_accuracy: 0.8400\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6047 - accuracy: 0.7327 - val_loss: 0.5484 - val_accuracy: 0.8400\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5948 - accuracy: 0.7189 - val_loss: 0.5482 - val_accuracy: 0.8400\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6059 - accuracy: 0.7005 - val_loss: 0.5480 - val_accuracy: 0.8400\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5966 - accuracy: 0.7143 - val_loss: 0.5478 - val_accuracy: 0.8400\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6099 - accuracy: 0.7005 - val_loss: 0.5476 - val_accuracy: 0.8400\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5889 - accuracy: 0.7235 - val_loss: 0.5474 - val_accuracy: 0.8400\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5979 - accuracy: 0.7189 - val_loss: 0.5472 - val_accuracy: 0.8400\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6028 - accuracy: 0.7051 - val_loss: 0.5471 - val_accuracy: 0.8400\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5972 - accuracy: 0.7005 - val_loss: 0.5469 - val_accuracy: 0.8400\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5904 - accuracy: 0.7189 - val_loss: 0.5467 - val_accuracy: 0.8400\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5975 - accuracy: 0.6728 - val_loss: 0.5465 - val_accuracy: 0.8400\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5922 - accuracy: 0.7235 - val_loss: 0.5463 - val_accuracy: 0.8400\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6135 - accuracy: 0.7051 - val_loss: 0.5461 - val_accuracy: 0.8400\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5708 - accuracy: 0.7880 - val_loss: 0.5459 - val_accuracy: 0.8400\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5911 - accuracy: 0.7281 - val_loss: 0.5458 - val_accuracy: 0.8400\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5885 - accuracy: 0.7512 - val_loss: 0.5456 - val_accuracy: 0.8400\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6088 - accuracy: 0.7051 - val_loss: 0.5454 - val_accuracy: 0.8400\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5923 - accuracy: 0.7189 - val_loss: 0.5452 - val_accuracy: 0.8400\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5784 - accuracy: 0.7512 - val_loss: 0.5450 - val_accuracy: 0.8400\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5941 - accuracy: 0.7419 - val_loss: 0.5448 - val_accuracy: 0.8400\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5930 - accuracy: 0.6774 - val_loss: 0.5446 - val_accuracy: 0.8400\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6124 - accuracy: 0.6682 - val_loss: 0.5445 - val_accuracy: 0.8400\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5888 - accuracy: 0.7373 - val_loss: 0.5443 - val_accuracy: 0.8400\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5960 - accuracy: 0.7189 - val_loss: 0.5441 - val_accuracy: 0.8400\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5747 - accuracy: 0.7327 - val_loss: 0.5439 - val_accuracy: 0.8400\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5867 - accuracy: 0.7281 - val_loss: 0.5437 - val_accuracy: 0.8400\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5832 - accuracy: 0.7465 - val_loss: 0.5435 - val_accuracy: 0.8400\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6033 - accuracy: 0.7143 - val_loss: 0.5433 - val_accuracy: 0.8400\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5971 - accuracy: 0.7327 - val_loss: 0.5432 - val_accuracy: 0.8400\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5994 - accuracy: 0.7327 - val_loss: 0.5430 - val_accuracy: 0.8400\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5917 - accuracy: 0.7373 - val_loss: 0.5428 - val_accuracy: 0.8400\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5757 - accuracy: 0.7189 - val_loss: 0.5426 - val_accuracy: 0.8400\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5930 - accuracy: 0.7373 - val_loss: 0.5424 - val_accuracy: 0.8400\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5831 - accuracy: 0.7005 - val_loss: 0.5422 - val_accuracy: 0.8400\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5871 - accuracy: 0.7465 - val_loss: 0.5420 - val_accuracy: 0.8400\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5853 - accuracy: 0.7143 - val_loss: 0.5418 - val_accuracy: 0.8400\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5882 - accuracy: 0.7281 - val_loss: 0.5417 - val_accuracy: 0.8400\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5879 - accuracy: 0.7005 - val_loss: 0.5415 - val_accuracy: 0.8400\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6059 - accuracy: 0.7051 - val_loss: 0.5413 - val_accuracy: 0.8400\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5844 - accuracy: 0.7189 - val_loss: 0.5411 - val_accuracy: 0.8400\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5720 - accuracy: 0.7558 - val_loss: 0.5409 - val_accuracy: 0.8400\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6057 - accuracy: 0.6959 - val_loss: 0.5407 - val_accuracy: 0.8400\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5981 - accuracy: 0.7419 - val_loss: 0.5405 - val_accuracy: 0.8400\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5937 - accuracy: 0.7005 - val_loss: 0.5403 - val_accuracy: 0.8400\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5911 - accuracy: 0.7143 - val_loss: 0.5402 - val_accuracy: 0.8400\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5957 - accuracy: 0.6728 - val_loss: 0.5400 - val_accuracy: 0.8400\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5861 - accuracy: 0.7281 - val_loss: 0.5398 - val_accuracy: 0.8400\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5906 - accuracy: 0.7097 - val_loss: 0.5396 - val_accuracy: 0.8400\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5808 - accuracy: 0.7373 - val_loss: 0.5394 - val_accuracy: 0.8400\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5775 - accuracy: 0.7512 - val_loss: 0.5392 - val_accuracy: 0.8400\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5952 - accuracy: 0.7097 - val_loss: 0.5390 - val_accuracy: 0.8400\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5973 - accuracy: 0.6912 - val_loss: 0.5389 - val_accuracy: 0.8400\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5839 - accuracy: 0.7558 - val_loss: 0.5387 - val_accuracy: 0.8400\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5737 - accuracy: 0.6866 - val_loss: 0.5385 - val_accuracy: 0.8400\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5879 - accuracy: 0.7051 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5785 - accuracy: 0.7419 - val_loss: 0.5381 - val_accuracy: 0.8000\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5930 - accuracy: 0.7281 - val_loss: 0.5379 - val_accuracy: 0.8000\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5778 - accuracy: 0.7373 - val_loss: 0.5377 - val_accuracy: 0.8000\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5918 - accuracy: 0.7235 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5765 - accuracy: 0.7465 - val_loss: 0.5374 - val_accuracy: 0.8000\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5829 - accuracy: 0.7327 - val_loss: 0.5372 - val_accuracy: 0.8000\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6009 - accuracy: 0.6682 - val_loss: 0.5370 - val_accuracy: 0.8000\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5974 - accuracy: 0.7281 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6026 - accuracy: 0.6912 - val_loss: 0.5366 - val_accuracy: 0.8000\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5976 - accuracy: 0.7419 - val_loss: 0.5364 - val_accuracy: 0.8000\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5940 - accuracy: 0.7235 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5947 - accuracy: 0.7327 - val_loss: 0.5361 - val_accuracy: 0.8000\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5789 - accuracy: 0.7465 - val_loss: 0.5359 - val_accuracy: 0.8000\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5849 - accuracy: 0.7281 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5795 - accuracy: 0.7189 - val_loss: 0.5355 - val_accuracy: 0.8000\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5863 - accuracy: 0.7143 - val_loss: 0.5353 - val_accuracy: 0.8000\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5951 - accuracy: 0.6912 - val_loss: 0.5351 - val_accuracy: 0.8000\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5855 - accuracy: 0.7189 - val_loss: 0.5349 - val_accuracy: 0.8000\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5894 - accuracy: 0.6912 - val_loss: 0.5347 - val_accuracy: 0.8000\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5732 - accuracy: 0.7696 - val_loss: 0.5345 - val_accuracy: 0.8000\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5836 - accuracy: 0.7189 - val_loss: 0.5344 - val_accuracy: 0.8000\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5985 - accuracy: 0.6498 - val_loss: 0.5342 - val_accuracy: 0.8000\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5649 - accuracy: 0.7189 - val_loss: 0.5340 - val_accuracy: 0.8000\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5864 - accuracy: 0.7281 - val_loss: 0.5338 - val_accuracy: 0.8000\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5980 - accuracy: 0.6820 - val_loss: 0.5336 - val_accuracy: 0.8000\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5783 - accuracy: 0.7097 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5877 - accuracy: 0.7281 - val_loss: 0.5332 - val_accuracy: 0.8000\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5844 - accuracy: 0.7143 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.5828 - accuracy: 0.7051 - val_loss: 0.5328 - val_accuracy: 0.8000\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5922 - accuracy: 0.7097 - val_loss: 0.5326 - val_accuracy: 0.8000\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5906 - accuracy: 0.7558 - val_loss: 0.5324 - val_accuracy: 0.8000\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5813 - accuracy: 0.7097 - val_loss: 0.5322 - val_accuracy: 0.8000\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5959 - accuracy: 0.6636 - val_loss: 0.5320 - val_accuracy: 0.8000\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5803 - accuracy: 0.7051 - val_loss: 0.5318 - val_accuracy: 0.8000\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5807 - accuracy: 0.7604 - val_loss: 0.5316 - val_accuracy: 0.8000\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.5723 - accuracy: 0.7465 - val_loss: 0.5314 - val_accuracy: 0.8000\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5897 - accuracy: 0.7143 - val_loss: 0.5313 - val_accuracy: 0.8000\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5759 - accuracy: 0.7419 - val_loss: 0.5311 - val_accuracy: 0.8000\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5900 - accuracy: 0.7235 - val_loss: 0.5309 - val_accuracy: 0.8000\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5638 - accuracy: 0.7604 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5725 - accuracy: 0.8065 - val_loss: 0.5305 - val_accuracy: 0.8000\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5776 - accuracy: 0.7419 - val_loss: 0.5303 - val_accuracy: 0.8000\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5920 - accuracy: 0.7097 - val_loss: 0.5301 - val_accuracy: 0.8000\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5830 - accuracy: 0.7281 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.5534 - accuracy: 0.7650 - val_loss: 0.5297 - val_accuracy: 0.8000\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.5915 - accuracy: 0.7235 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.5745 - accuracy: 0.7281 - val_loss: 0.5294 - val_accuracy: 0.8000\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.5913 - accuracy: 0.7005 - val_loss: 0.5292 - val_accuracy: 0.8000\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.5870 - accuracy: 0.7143 - val_loss: 0.5290 - val_accuracy: 0.8000\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.5827 - accuracy: 0.7281 - val_loss: 0.5288 - val_accuracy: 0.8000\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5677 - accuracy: 0.7327 - val_loss: 0.5287 - val_accuracy: 0.8000\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5671 - accuracy: 0.7419 - val_loss: 0.5285 - val_accuracy: 0.8000\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5730 - accuracy: 0.7558 - val_loss: 0.5283 - val_accuracy: 0.8000\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5696 - accuracy: 0.7558 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5917 - accuracy: 0.7051 - val_loss: 0.5279 - val_accuracy: 0.8000\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5758 - accuracy: 0.7051 - val_loss: 0.5277 - val_accuracy: 0.8000\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5742 - accuracy: 0.7327 - val_loss: 0.5276 - val_accuracy: 0.8000\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5775 - accuracy: 0.7189 - val_loss: 0.5274 - val_accuracy: 0.8000\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5795 - accuracy: 0.7143 - val_loss: 0.5272 - val_accuracy: 0.8000\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5777 - accuracy: 0.7235 - val_loss: 0.5270 - val_accuracy: 0.8000\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5785 - accuracy: 0.7097 - val_loss: 0.5268 - val_accuracy: 0.8000\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5595 - accuracy: 0.8065 - val_loss: 0.5267 - val_accuracy: 0.8000\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5680 - accuracy: 0.7558 - val_loss: 0.5265 - val_accuracy: 0.8000\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5889 - accuracy: 0.7051 - val_loss: 0.5263 - val_accuracy: 0.8000\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5626 - accuracy: 0.7696 - val_loss: 0.5261 - val_accuracy: 0.8000\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5694 - accuracy: 0.7143 - val_loss: 0.5259 - val_accuracy: 0.8000\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5651 - accuracy: 0.7419 - val_loss: 0.5257 - val_accuracy: 0.8000\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5725 - accuracy: 0.7143 - val_loss: 0.5255 - val_accuracy: 0.8000\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5803 - accuracy: 0.7465 - val_loss: 0.5254 - val_accuracy: 0.8000\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5840 - accuracy: 0.6912 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5769 - accuracy: 0.7327 - val_loss: 0.5250 - val_accuracy: 0.8000\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5834 - accuracy: 0.7327 - val_loss: 0.5248 - val_accuracy: 0.8000\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5804 - accuracy: 0.7373 - val_loss: 0.5246 - val_accuracy: 0.8000\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5677 - accuracy: 0.7604 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5921 - accuracy: 0.6959 - val_loss: 0.5242 - val_accuracy: 0.8000\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5874 - accuracy: 0.7189 - val_loss: 0.5241 - val_accuracy: 0.8000\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5595 - accuracy: 0.7512 - val_loss: 0.5239 - val_accuracy: 0.8000\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5564 - accuracy: 0.7650 - val_loss: 0.5237 - val_accuracy: 0.8000\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5653 - accuracy: 0.7558 - val_loss: 0.5235 - val_accuracy: 0.8000\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5592 - accuracy: 0.7972 - val_loss: 0.5233 - val_accuracy: 0.8000\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5811 - accuracy: 0.7235 - val_loss: 0.5231 - val_accuracy: 0.8000\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5807 - accuracy: 0.6912 - val_loss: 0.5229 - val_accuracy: 0.8000\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5634 - accuracy: 0.7558 - val_loss: 0.5227 - val_accuracy: 0.8000\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5591 - accuracy: 0.7327 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5684 - accuracy: 0.7097 - val_loss: 0.5224 - val_accuracy: 0.8000\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5497 - accuracy: 0.7880 - val_loss: 0.5222 - val_accuracy: 0.8000\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5828 - accuracy: 0.7143 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5720 - accuracy: 0.7097 - val_loss: 0.5218 - val_accuracy: 0.8000\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5796 - accuracy: 0.6959 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5778 - accuracy: 0.7419 - val_loss: 0.5214 - val_accuracy: 0.8000\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5686 - accuracy: 0.7788 - val_loss: 0.5212 - val_accuracy: 0.8000\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5714 - accuracy: 0.7097 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5675 - accuracy: 0.7373 - val_loss: 0.5208 - val_accuracy: 0.8000\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5834 - accuracy: 0.7051 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5820 - accuracy: 0.7097 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5687 - accuracy: 0.7281 - val_loss: 0.5202 - val_accuracy: 0.8000\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5800 - accuracy: 0.7143 - val_loss: 0.5201 - val_accuracy: 0.8000\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5515 - accuracy: 0.7419 - val_loss: 0.5199 - val_accuracy: 0.8000\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5709 - accuracy: 0.7327 - val_loss: 0.5197 - val_accuracy: 0.8000\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5611 - accuracy: 0.7465 - val_loss: 0.5195 - val_accuracy: 0.8000\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5733 - accuracy: 0.7281 - val_loss: 0.5193 - val_accuracy: 0.8000\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5659 - accuracy: 0.7327 - val_loss: 0.5191 - val_accuracy: 0.8000\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5817 - accuracy: 0.7373 - val_loss: 0.5189 - val_accuracy: 0.8000\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5757 - accuracy: 0.7327 - val_loss: 0.5187 - val_accuracy: 0.8000\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5713 - accuracy: 0.7235 - val_loss: 0.5186 - val_accuracy: 0.8000\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5585 - accuracy: 0.7465 - val_loss: 0.5184 - val_accuracy: 0.8000\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5607 - accuracy: 0.7696 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5505 - accuracy: 0.7696 - val_loss: 0.5180 - val_accuracy: 0.8000\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5711 - accuracy: 0.7373 - val_loss: 0.5178 - val_accuracy: 0.8000\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5829 - accuracy: 0.7327 - val_loss: 0.5176 - val_accuracy: 0.8000\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5533 - accuracy: 0.7650 - val_loss: 0.5175 - val_accuracy: 0.8000\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5761 - accuracy: 0.7143 - val_loss: 0.5173 - val_accuracy: 0.8000\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5696 - accuracy: 0.7373 - val_loss: 0.5171 - val_accuracy: 0.8000\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5442 - accuracy: 0.8018 - val_loss: 0.5169 - val_accuracy: 0.8000\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5668 - accuracy: 0.7327 - val_loss: 0.5167 - val_accuracy: 0.8000\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5791 - accuracy: 0.7281 - val_loss: 0.5165 - val_accuracy: 0.8000\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5612 - accuracy: 0.7512 - val_loss: 0.5163 - val_accuracy: 0.8000\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5559 - accuracy: 0.7742 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5771 - accuracy: 0.7281 - val_loss: 0.5159 - val_accuracy: 0.8000\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5710 - accuracy: 0.7465 - val_loss: 0.5157 - val_accuracy: 0.8000\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.5808 - accuracy: 0.7281 - val_loss: 0.5156 - val_accuracy: 0.8000\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5767 - accuracy: 0.7327 - val_loss: 0.5154 - val_accuracy: 0.8000\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5777 - accuracy: 0.7189 - val_loss: 0.5152 - val_accuracy: 0.8000\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5799 - accuracy: 0.7097 - val_loss: 0.5150 - val_accuracy: 0.8000\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5590 - accuracy: 0.7373 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5745 - accuracy: 0.7327 - val_loss: 0.5146 - val_accuracy: 0.8000\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5572 - accuracy: 0.7419 - val_loss: 0.5144 - val_accuracy: 0.8000\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5707 - accuracy: 0.7558 - val_loss: 0.5142 - val_accuracy: 0.8000\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5564 - accuracy: 0.7650 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5591 - accuracy: 0.7327 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5758 - accuracy: 0.7189 - val_loss: 0.5136 - val_accuracy: 0.8000\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5728 - accuracy: 0.7097 - val_loss: 0.5135 - val_accuracy: 0.8000\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5952 - accuracy: 0.7051 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5852 - accuracy: 0.7419 - val_loss: 0.5131 - val_accuracy: 0.8000\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5695 - accuracy: 0.7143 - val_loss: 0.5129 - val_accuracy: 0.8000\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5809 - accuracy: 0.7097 - val_loss: 0.5127 - val_accuracy: 0.8000\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5639 - accuracy: 0.7650 - val_loss: 0.5125 - val_accuracy: 0.8000\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5644 - accuracy: 0.7235 - val_loss: 0.5123 - val_accuracy: 0.8000\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5450 - accuracy: 0.7696 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5737 - accuracy: 0.7465 - val_loss: 0.5119 - val_accuracy: 0.8000\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.5928 - accuracy: 0.6959 - val_loss: 0.5117 - val_accuracy: 0.8000\n",
            "Epoch 913: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "APqB9_Snwm0b",
        "outputId": "7b452dc8-327d-4cc3-f7df-5e99f6ddd77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Sa9dZ5zHwnwn",
        "outputId": "2522174f-24ed-4940-db40-bd61da87a69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "pred = tf.cast(tf.round(pred), dtype=tf.int32).numpy().reshape(61)"
      ],
      "metadata": {
        "id": "tBGoEm40BBbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ce3b8d-8a37-407f-ea71-b4708bcc548b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True heart attack chances      :\", y_test[:15])\n",
        "print(\"Predicted heart attack chances :\", pred[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xADmLTp4Bln0",
        "outputId": "5dc2c652-25ec-4e0f-82ee-29dd1b57b64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True heart attack chances      : [0 0 1 0 1 1 1 0 0 1 1 1 1 0 1]\n",
            "Predicted heart attack chances : [0 1 1 0 1 1 1 0 0 0 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc=accuracy_score(y_test, pred) * 100\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5T9a85yFtQu",
        "outputId": "71b25ab9-aa23-4ab7-8dee-6ce228bf5687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86.88524590163934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification report:\\n', classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHidyxO8OkCr",
        "outputId": "61785a5d-2b74-41bf-c7bb-a4f4e504c755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86        29\n",
            "           1       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.87        61\n",
            "   macro avg       0.87      0.87      0.87        61\n",
            "weighted avg       0.87      0.87      0.87        61\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"heart_model.h5\")\n",
        "model.save(\"heart_model.json\")\n",
        "pickle.dump(model, open('heart_model.pkl','wb'))\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d8PEFtCgbwo",
        "outputId": "4815aecf-2ed3-4b35-963e-a7eb600a2b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    }
  ]
}